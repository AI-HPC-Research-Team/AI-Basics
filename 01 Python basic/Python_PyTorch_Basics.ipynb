{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "574821c8",
      "metadata": {
        "id": "574821c8"
      },
      "source": [
        "# Python & PyTorch Basics\n",
        "\n",
        "**Recommended runtime:** Google Colab (GPU optional) or local JupyterLab.\n",
        "\n",
        "- ✅ Python basics: syntax, containers, functions, files, iteration & higher-order functions\n",
        "- ✅ PyTorch basics: Tensor, GPU device, Autograd, `nn.Module`, `DataLoader`, train/eval loops\n",
        "- ✅ Example 1 (NLP): Bag-of-Words small example (from scratch)\n",
        "- ✅ Example 2 (CV): FashionMNIST quick training (MLP; runs on CPU/GPU)\n",
        "- ⛳ Optional: Tiny BERT fine-tuning (1 epoch) with `transformers`\n",
        "\n",
        "> Notes: cells try to **gracefully degrade**—if a tool is missing, the notebook prints alternatives or skips steps.  \n",
        "> Last updated: 2025-11-12 10:12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a557dcb",
      "metadata": {
        "id": "9a557dcb"
      },
      "source": [
        "## 0) Runtime Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b137fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64b137fd",
        "outputId": "db89e612-0733-43eb-a472-29d0ee869340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.12.12\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "In Colab: True\n",
            "PyTorch: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, sys, platform\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "IN_COLAB = 'COLAB_GPU' in os.environ or 'COLAB_RELEASE_TAG' in os.environ\n",
        "print(\"In Colab:\", IN_COLAB)\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch:\", torch.__version__)\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "except Exception as e:\n",
        "    print(\"PyTorch not found:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fmXF63qkWOKy",
      "metadata": {
        "id": "fmXF63qkWOKy"
      },
      "source": [
        "## 1) **Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3XkvLfwkWJx4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XkvLfwkWJx4",
        "outputId": "123987ff-d092-4e20-e861-c46cb71fb48c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/494.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m491.5/494.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qq -U transformers datasets accelerate pyarrow==19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a3a7f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86a3a7f9",
        "outputId": "3ebbd36d-36cf-4cc6-f17c-2b95ff63d9f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy: 2.0.2\n",
            "Pandas: 2.2.2\n",
            "Matplotlib: 3.10.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"Matplotlib:\", plt.matplotlib.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ee622c",
      "metadata": {
        "id": "09ee622c"
      },
      "source": [
        "## 2) Python Basics · Syntax / Containers / Functions / Files / Iteration\n",
        "Covers numbers/strings, lists/tuples/dicts, functions/args, loops, file I/O, list comprehensions, and basic higher-order functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52839ca9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52839ca9",
        "outputId": "29cbac15-1b1f-4db4-8512-964a225bbeed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.5 HELLO, PYTHON! [1, 2, 3] ('a', 1) 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Numbers, strings, lists/tuples/dicts\n",
        "x = 5\n",
        "y = 2.5\n",
        "s = \"Hello, Python!\"\n",
        "lst = [1, 2, 3]\n",
        "tup = ('a', 1)\n",
        "d = {'k': 3, 'v': 9}\n",
        "print(x+y, s.upper(), lst, tup, d['k'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "778f25dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "778f25dc",
        "outputId": "4f47f57b-891e-4313-c9d9-b900c86d5394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi, Dr. Smith\n",
            "Hi, Prof. Ada!!!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Functions & keyword-only args\n",
        "def greet(name, title=\"Dr.\", *, excited=False):\n",
        "    msg = f\"Hi, {title} {name}\"\n",
        "    return msg + \"!!!\" if excited else msg\n",
        "\n",
        "print(greet(\"Smith\"))\n",
        "print(greet(\"Ada\", title=\"Prof.\", excited=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1dadff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e1dadff",
        "outputId": "1bc7313a-2549-4e07-b006-58e9ed2f0f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "squares: [0, 1, 4, 9, 16, 25]\n",
            "even_squares: [0, 4, 16]\n",
            "sum_squares: 55\n",
            "fib(20): 6765\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Loops, comprehensions, higher-order utilities\n",
        "from functools import lru_cache, reduce\n",
        "squares = [i*i for i in range(6)]\n",
        "even_squares = [z for z in squares if z % 2 == 0]\n",
        "sum_squares = reduce(lambda a,b: a+b, squares, 0)\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def fib(n):\n",
        "    return n if n < 2 else fib(n-1)+fib(n-2)\n",
        "\n",
        "print(\"squares:\", squares)\n",
        "print(\"even_squares:\", even_squares)\n",
        "print(\"sum_squares:\", sum_squares)\n",
        "print(\"fib(20):\", fib(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57342657",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57342657",
        "outputId": "69365a2e-f599-485e-f00c-aca0eebc3afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File content:\n",
            "First line\n",
            "Second line\n",
            "Third line\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Simple file I/O\n",
        "from pathlib import Path\n",
        "p = Path(\"demo.txt\")\n",
        "p.write_text(\"First line\\nSecond line\\nThird line\\n\", encoding=\"utf-8\")\n",
        "print(\"File content:\")\n",
        "print(p.read_text(encoding=\"utf-8\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a50ec7c4",
      "metadata": {
        "id": "a50ec7c4"
      },
      "source": [
        "## 3) PyTorch Basics · Tensor / GPU / Autograd / nn\n",
        "Goal: get a quick grasp of tensors, device moves, broadcasting, autograd, and building a minimal `nn.Module`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e94015b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e94015b",
        "outputId": "15692b04-5ead-48dc-cde8-701b7e0aa014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "a: torch.Size([2, 3]) b: torch.Size([3, 2]) c: torch.Size([2, 2])\n",
            "Broadcast: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "a = torch.randn(2,3, device=device)\n",
        "b = torch.randn(3,2, device=device)\n",
        "c = a @ b    # matmul\n",
        "print(\"a:\", a.shape, \"b:\", b.shape, \"c:\", c.shape)\n",
        "x = torch.arange(6, dtype=torch.float32, device=device).reshape(2,3)\n",
        "v = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
        "print(\"Broadcast:\", (x+v).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa343b8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa343b8c",
        "outputId": "9925138f-dcde-4476-9ce0-0ca76f0a2abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor([-0.7404, -0.1764,  0.4393,  0.4072], requires_grad=True)\n",
            "x.grad: tensor([-1.4807, -0.3528,  0.8787,  0.8144])\n",
            "Detached requires_grad: False\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Autograd demo: y = (x^2).sum() -> dy/dx = 2x\n",
        "x = torch.randn(4, requires_grad=True)\n",
        "y = (x**2).sum()\n",
        "y.backward()\n",
        "print(\"x:\", x)\n",
        "print(\"x.grad:\", x.grad)\n",
        "# Detach to stop tracking\n",
        "z = x.detach()\n",
        "print(\"Detached requires_grad:\", z.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45fb13a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45fb13a6",
        "outputId": "02e0436a-0ba8-4746-9e59-39b66d9ac483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TinyNet(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=16, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "logits: torch.Size([5, 2])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Minimal nn.Module\n",
        "import torch.nn as nn\n",
        "class TinyNet(nn.Module):\n",
        "    def __init__(self, d_in=10, d_h=16, d_out=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_in, d_h),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_h, d_out)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = TinyNet().to(device)\n",
        "print(model)\n",
        "dummy = torch.randn(5, 10, device=device)\n",
        "logits = model(dummy)\n",
        "print(\"logits:\", logits.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63adf89c",
      "metadata": {
        "id": "63adf89c"
      },
      "source": [
        "## 4) Example #1 · Bag-of-Words (from scratch, tiny dataset)\n",
        "- Tokenization → vocab → vectorization → linear classifier (`nn.Linear`).\n",
        "- Good for showing the full pipeline: preprocessing → tensors → training → evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10c06f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a10c06f8",
        "outputId": "f8bf9320-3e4e-4270-d584-435c2c123687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 020 loss=0.0089\n",
            "epoch 040 loss=0.0026\n",
            "epoch 060 loss=0.0018\n",
            "epoch 080 loss=0.0015\n",
            "Test acc: 1.0\n",
            "Pred vs true: [(0, 0), (1, 1)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re, random, torch, torch.nn as nn, torch.optim as optim\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data = [\n",
        "    (\"deep learning changes everything\", 1),\n",
        "    (\"neural networks are powerful\", 1),\n",
        "    (\"this movie was fantastic\", 1),\n",
        "    (\"awful plot and bad acting\", 0),\n",
        "    (\"terrible movie and boring\", 0),\n",
        "    (\"an excellent and enjoyable film\", 1),\n",
        "    (\"bad direction and poor script\", 0),\n",
        "    (\"i loved the visuals\", 1),\n",
        "]\n",
        "\n",
        "random.shuffle(data)\n",
        "\n",
        "def tokenize(s): return re.findall(r\"[a-z]+\", s.lower())\n",
        "vocab = {}\n",
        "for s,_ in data:\n",
        "    for tok in tokenize(s):\n",
        "        if tok not in vocab: vocab[tok] = len(vocab)\n",
        "V = len(vocab)\n",
        "\n",
        "def vectorize(s):\n",
        "    x = torch.zeros(V)\n",
        "    for tok in tokenize(s):\n",
        "        if tok in vocab:\n",
        "            x[vocab[tok]] += 1.0\n",
        "    return x\n",
        "\n",
        "X = torch.stack([vectorize(s) for s,_ in data])\n",
        "y = torch.tensor([lbl for _,lbl in data], dtype=torch.long)\n",
        "n_train = int(0.75*len(data))\n",
        "Xtr, Xte = X[:n_train], X[n_train:]\n",
        "ytr, yte = y[:n_train], y[n_train:]\n",
        "\n",
        "model = nn.Sequential(nn.Linear(V, 2)).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "Xtr_d = Xtr.to(device)\n",
        "ytr_d = ytr.to(device)\n",
        "for epoch in range(80):\n",
        "    opt.zero_grad()\n",
        "    logits = model(Xtr_d)\n",
        "    loss = loss_fn(logits, ytr_d)\n",
        "    loss.backward(); opt.step()\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        print(f\"epoch {epoch+1:03d} loss={loss.item():.4f}\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(X, y):\n",
        "    logits = model(X.to(device))\n",
        "    pred = logits.argmax(dim=1).cpu()\n",
        "    acc = (pred == y).float().mean().item()\n",
        "    return acc, pred\n",
        "\n",
        "acc, pred = evaluate(Xte, yte)\n",
        "print(\"Test acc:\", round(acc, 3))\n",
        "print(\"Pred vs true:\", list(zip(pred.tolist(), yte.tolist())))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bfc0c44",
      "metadata": {
        "id": "1bfc0c44"
      },
      "source": [
        "## 5) Example #2 · FashionMNIST (MLP quick training)\n",
        "- Pipeline: `Dataset/DataLoader → Model → Loss/Optimizer → Train/Eval`\n",
        "- Runs on CPU by default; uses GPU if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6624c117",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6624c117",
        "outputId": "1f2566d4-0d5c-4992-9895-67fbdf6dbc1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 | train acc 0.808 | val acc 0.844\n",
            "epoch 2 | train acc 0.858 | val acc 0.850\n",
            "epoch 3 | train acc 0.871 | val acc 0.861\n",
            "Saved to checkpoints/fmnist_mlp.pt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim, os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tfm = transforms.Compose([transforms.ToTensor()])\n",
        "train_ds = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=tfm)\n",
        "test_ds  = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=tfm)\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "model = MLP().to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    total, correct, total_loss = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = loss_fn(logits, yb)\n",
        "        loss.backward(); opt.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        correct += (logits.argmax(1) == yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total, correct, total_loss = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = loss_fn(logits, yb)\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        correct += (logits.argmax(1) == yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "for epoch in range(3):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader)\n",
        "    te_loss, te_acc = evaluate(model, test_loader)\n",
        "    print(f\"epoch {epoch+1} | train acc {tr_acc:.3f} | val acc {te_acc:.3f}\")\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "torch.save(model.state_dict(), \"checkpoints/fmnist_mlp.pt\")\n",
        "print(\"Saved to checkpoints/fmnist_mlp.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92afd92f",
      "metadata": {
        "id": "92afd92f"
      },
      "source": [
        "## 6) (Optional) Tiny BERT Fine-tuning\n",
        "> Requires internet to install `transformers` / `datasets`. Runtime depends on your environment.\n",
        "This cell fine-tunes **`distilbert-base-uncased`** for 1 epoch on a small sample, demonstrating the Trainer API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc4bb66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564,
          "referenced_widgets": [
            "d508a040ae69476698f22da2560ed71d",
            "1788b823aad7405a8e9c09194f4c609f",
            "2b737967820f40d583db1ba7393fcaea",
            "2476965963f6473db9658b6701d93b5f",
            "0fc6987b7a6a47a6a6b3741e15d867e1",
            "a9aa036c134a4ee9961eb91f8dbf01f6",
            "a59ea07860e6413bae17c0f5c6207d8b",
            "3c4afd77cc72484cb0ae3dd1b162647b",
            "c6539a0195d84aa4a4ab33fd8eeca555",
            "8937b9fa31ed4fdea037a3da80849a88",
            "3a31872daa6d43b1a127d3cb3f00a6e5",
            "cecad18f56b74bbdb81ade96dfa17c87",
            "21bab5a625e04ae38b009e85c5b4f772",
            "e30b0028847640f49587369a80e6d710",
            "2bc2eabb036043089d17cc8d78a40041",
            "66a4f271b2eb4bf792f277937942e7e6",
            "be9964ace830427399e42755d9da98b3",
            "b38e21067693496d9ae4ca84a3c10c33",
            "11807e093b3a4245b170865e92e49d7f",
            "f9482d2fcb1f407684887fa88ef4e269",
            "703a64bcb4c64805896cc35c9c20d9f6",
            "5cb143b34cb94e20b2e1c545ecf52aa5"
          ]
        },
        "id": "bbc4bb66",
        "outputId": "0371cd69-44f9-4e6d-df59-2bdb615a1d56"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d508a040ae69476698f22da2560ed71d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cecad18f56b74bbdb81ade96dfa17c87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1113834900.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(model=model, args=args,\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlanjinrao\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251112_143045-9twmy09m</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lanjinrao/huggingface/runs/9twmy09m' target=\"_blank\">astral-waterfall-1</a></strong> to <a href='https://wandb.ai/lanjinrao/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/lanjinrao/huggingface' target=\"_blank\">https://wandb.ai/lanjinrao/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/lanjinrao/huggingface/runs/9twmy09m' target=\"_blank\">https://wandb.ai/lanjinrao/huggingface/runs/9twmy09m</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='95' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 95/125 11:13 < 03:37, 0.14 it/s, Epoch 0.75/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='99' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 99/125 11:33 < 03:05, 0.14 it/s, Epoch 0.78/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "RUN_BERT = True  # Set to True to actually run the cell\n",
        "if RUN_BERT:\n",
        "    from datasets import load_dataset\n",
        "    from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "    ds = load_dataset(\"ag_news\")\n",
        "    small_train = ds[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "    small_test  = ds[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "    tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "    def tokenize(batch): return tok(batch[\"text\"], truncation=True)\n",
        "    small_train = small_train.map(tokenize, batched=True)\n",
        "    small_test  = small_test.map(tokenize, batched=True)\n",
        "\n",
        "    collate = DataCollatorWithPadding(tokenizer=tok)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"bert_demo\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=32,\n",
        "        learning_rate=2e-5,\n",
        "        logging_steps=50,\n",
        "        fp16=False\n",
        "    )\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        import numpy as np\n",
        "        logits, labels = eval_pred\n",
        "        preds = logits.argmax(axis=-1)\n",
        "        acc = (preds == labels).astype(float).mean().item()\n",
        "        return {\"accuracy\": acc}\n",
        "\n",
        "    trainer = Trainer(model=model, args=args,\n",
        "                      train_dataset=small_train, eval_dataset=small_test,\n",
        "                      tokenizer=tok, data_collator=collate,\n",
        "                      compute_metrics=compute_metrics)\n",
        "    trainer.train()\n",
        "    print(trainer.evaluate())\n",
        "else:\n",
        "    print(\"Set RUN_BERT=True to run the tiny BERT fine-tuning demo.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4058bcd6",
      "metadata": {
        "id": "4058bcd6"
      },
      "source": [
        "---\n",
        "\n",
        "### Appendix · Quick Cheatsheet\n",
        "- **conda env**  \n",
        "`conda create -n my_env python=3.10` · `conda activate my_env` · `conda install -c conda-forge numpy`  \n",
        "`conda env export > env.yml` · `conda env create -f env.yml`\n",
        "- **mamba**: a faster drop-in replacement for conda\n",
        "- **pip**: `pip install packagename` (prefer conda first when mixing)\n",
        "- **PyTorch install**: see https://pytorch.org/get-started/ for CUDA-matched commands\n",
        "- **Training loop quartet**: `Dataset/DataLoader` → `Model(nn.Module)` → `Loss` → `Optimizer.step()`\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fc6987b7a6a47a6a6b3741e15d867e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11807e093b3a4245b170865e92e49d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1788b823aad7405a8e9c09194f4c609f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9aa036c134a4ee9961eb91f8dbf01f6",
            "placeholder": "​",
            "style": "IPY_MODEL_a59ea07860e6413bae17c0f5c6207d8b",
            "value": "Map: 100%"
          }
        },
        "21bab5a625e04ae38b009e85c5b4f772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be9964ace830427399e42755d9da98b3",
            "placeholder": "​",
            "style": "IPY_MODEL_b38e21067693496d9ae4ca84a3c10c33",
            "value": "Map: 100%"
          }
        },
        "2476965963f6473db9658b6701d93b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8937b9fa31ed4fdea037a3da80849a88",
            "placeholder": "​",
            "style": "IPY_MODEL_3a31872daa6d43b1a127d3cb3f00a6e5",
            "value": " 2000/2000 [00:00&lt;00:00, 3646.74 examples/s]"
          }
        },
        "2b737967820f40d583db1ba7393fcaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c4afd77cc72484cb0ae3dd1b162647b",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6539a0195d84aa4a4ab33fd8eeca555",
            "value": 2000
          }
        },
        "2bc2eabb036043089d17cc8d78a40041": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703a64bcb4c64805896cc35c9c20d9f6",
            "placeholder": "​",
            "style": "IPY_MODEL_5cb143b34cb94e20b2e1c545ecf52aa5",
            "value": " 1000/1000 [00:00&lt;00:00, 3740.61 examples/s]"
          }
        },
        "3a31872daa6d43b1a127d3cb3f00a6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4afd77cc72484cb0ae3dd1b162647b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb143b34cb94e20b2e1c545ecf52aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66a4f271b2eb4bf792f277937942e7e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "703a64bcb4c64805896cc35c9c20d9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8937b9fa31ed4fdea037a3da80849a88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59ea07860e6413bae17c0f5c6207d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9aa036c134a4ee9961eb91f8dbf01f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38e21067693496d9ae4ca84a3c10c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be9964ace830427399e42755d9da98b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6539a0195d84aa4a4ab33fd8eeca555": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cecad18f56b74bbdb81ade96dfa17c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21bab5a625e04ae38b009e85c5b4f772",
              "IPY_MODEL_e30b0028847640f49587369a80e6d710",
              "IPY_MODEL_2bc2eabb036043089d17cc8d78a40041"
            ],
            "layout": "IPY_MODEL_66a4f271b2eb4bf792f277937942e7e6"
          }
        },
        "d508a040ae69476698f22da2560ed71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1788b823aad7405a8e9c09194f4c609f",
              "IPY_MODEL_2b737967820f40d583db1ba7393fcaea",
              "IPY_MODEL_2476965963f6473db9658b6701d93b5f"
            ],
            "layout": "IPY_MODEL_0fc6987b7a6a47a6a6b3741e15d867e1"
          }
        },
        "e30b0028847640f49587369a80e6d710": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11807e093b3a4245b170865e92e49d7f",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9482d2fcb1f407684887fa88ef4e269",
            "value": 1000
          }
        },
        "f9482d2fcb1f407684887fa88ef4e269": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
